# -*- coding: utf-8 -*-
"""Behavioral Cloning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j-qFpDL0Bf37JMjdfcM5wNI87duUgtVo

# Behavioral Cloning
"""

# after run this cell, restart runtime for changes to effect
#!apt install -y -q graphviz
#!pip install -q graphviz
#!pip install -q pydot

import sys
import keras
import tensorflow as tf
import numpy as np

# check version compatibility with local
print('Python ersion:', sys.version)
print('Keras version:', keras.__version__)
print('Tesorflow version:', tf.__version__)
print('Numpy version:', np.__version__)

"""## Prepare Data"""

#!wget https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip
#!unzip -q -o data.zip

import csv

def read_logs(data_paths):
  lines = []
  for data_path in data_paths:
    with open(data_path + 'driving_log.csv', 'r') as file:
      reader = csv.reader(file)
      for line in reader:
        if line[0] == 'center':
          # print headers for debugging
          print(line)
          # don't add headers
          continue
        line = [data_path + col.strip() if i < 3 else col.strip() for i, col in enumerate(line)]
        lines.append(line)
  return lines

data_paths = ['data/']
lines = read_logs(data_paths)

# print first line for debugging
print(lines[0])

"""## Load Data"""

import numpy as np
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline

def read_image(path):
  return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB) 

def read_data(lines, angle_correction):
  images = []
  steerings = []
  for line in lines:
    # load center image in RGB
    img = read_image(line[0])
    steering = float(line[3])

    # add center image
    images.append(img)
    steerings.append(steering)

    # add flipped of center image
    images.append(np.fliplr(img))
    steerings.append(-steering)

    # load left image
    left_img = read_image(line[1])
    left_steering = steering + angle_correction

    # add left image
    images.append(left_img)
    steerings.append(left_steering)

    # add flipped of left image
    #images.append(np.fliplr(left_img))
    #steerings.append(-left_steering)

    # load right image
    right_img = read_image(line[2])
    right_steering = steering - angle_correction

    # add right image
    images.append(right_img)
    steerings.append(right_steering)

    # add flipped of right image
    #images.append(np.fliplr(right_img))
    #steerings.append(-right_steering)

  # show some example images
  print(steerings[2])
  plt.figure()
  plt.imshow(images[2])

  print(steerings[3])
  plt.figure()
  plt.imshow(images[3])

  # convert and return them to numpy arrays
  return np.array(images), np.array(steerings)

"""## Data Generators"""

from random import shuffle
from sklearn.model_selection import train_test_split

def generate_samples(lines):
  samples = []
  for line in lines:
    samples.append({'line': line, 'image': 'center', 'flipped': False})
    samples.append({'line': line, 'image': 'center', 'flipped': True})
    samples.append({'line': line, 'image': 'left', 'flipped': False})
    samples.append({'line': line, 'image': 'left', 'flipped': True})
    samples.append({'line': line, 'image': 'right', 'flipped': False})
    samples.append({'line': line, 'image': 'right', 'flipped': True})
  return samples

def data_generator(samples, angle_correction, batch_size=32):
  num_samples = len(samples)
  while 1:
    shuffle(samples)
    for offset in range(0, num_samples, batch_size):
      batch_samples = samples[offset:offset+batch_size]
      images = []
      steerings = []
      for sample in batch_samples:
        path_index = 0
        if sample['image'] == 'left':
          path_index = 1
        elif sample['image'] == 'right':
          path_index = 2
        
        # load image in RGB
        img = read_image(sample['line'][path_index])
        steering = float(sample['line'][3])
        
        # correct steering angle if frame does not come from center camera
        if path_index != 0:
          if path_index == 1:
            steering += angle_correction
          else:
            steering -= angle_correction
        
        if sample['flipped']:
          img = np.fliplr(img)
          steering = -steering
        
        images.append(img)
        steerings.append(steering)
      yield np.array(images), np.array(steerings)

angle_correction = 0.07
#X_train, y_train = read_data(lines, angle_correction)

# print info for debugging
#print(X_train.shape, y_train.shape, X_train.dtype)

batch_size = 32
samples = generate_samples(lines)
train_samples, valid_samples = train_test_split(samples, test_size = 0.2)
train_generator = data_generator(train_samples, angle_correction, batch_size=batch_size)
valid_generator = data_generator(valid_samples, angle_correction, batch_size=batch_size)

"""## Models"""

from keras.models import Sequential
from keras.layers import Flatten, Dense, Lambda, Dropout
from keras.layers import Conv2D, MaxPooling2D, Cropping2D

def LeNet(input_shape):
  model = Sequential()
  model.add(Cropping2D(((70, 25), (0, 0)), input_shape=input_shape))
  model.add(Lambda(lambda x: x / 255.0 - 0.5))
  model.add(Conv2D(6, (5, 5), activation='relu'))
  model.add(MaxPooling2D())
  model.add(Conv2D(6, (5, 5), activation='relu'))
  model.add(MaxPooling2D())
  model.add(Flatten())
  model.add(Dense(120))
  model.add(Dense(84))
  model.add(Dense(1))
  return model

def NvidiaNet(input_shape):
  model = Sequential()
  model.add(Cropping2D(((70, 25), (0, 0)), input_shape=input_shape))
  model.add(Lambda(lambda x: x / 255.0 - 0.5))
  model.add(Conv2D(24, (5, 5), strides=(2, 2), activation='relu'))
  model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='relu'))
  model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='relu'))
  model.add(Dropout(0.25))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(Dropout(0.25))
  model.add(Flatten())
  model.add(Dense(100))
  model.add(Dense(50))
  model.add(Dropout(0.25))
  model.add(Dense(10))
  model.add(Dense(1))
  return model

input_shape = (160, 320, 3)
#model = LeNet(input_shape)
model = NvidiaNet(input_shape)
model.compile(loss='mse', optimizer='adam')

"""## Train Model"""

from keras.callbacks import ModelCheckpoint

checkpointer = ModelCheckpoint(filepath='model.h5', verbose=1, save_best_only=True)
#history = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=10, callbacks=[checkpointer])
history = model.fit_generator(train_generator, steps_per_epoch=len(train_samples)/batch_size, epochs=10, validation_data=valid_generator, validation_steps=len(valid_samples)/batch_size, callbacks=[checkpointer])

"""## Visualize Training History"""

# Plot training & validation loss values
#plt.plot(history.history['loss'])
#plt.plot(history.history['val_loss'])
#plt.title('Model loss')
#plt.ylabel('Loss')
#plt.xlabel('Epoch')
#plt.legend(['Train', 'Valid'], loc='upper right')
#plt.show()

"""## Visualize Model"""

#from keras.utils import plot_model
#plot_model(model, to_file='model.png', show_shapes=True)